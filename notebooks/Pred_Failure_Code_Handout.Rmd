---
title: "Code_Handout"
author: "Jackie Vogel, Sarah Millard, Ignacio Luque, Leo Walker"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# installing caret for train/test split
library(caret)
library(nnet)
library(corrplot)
library(ggplot2)
library(car)
```

## Multinomial Logistic Regression

This R Markdown demonstrates how to use Multinomial Logistic Regression on a small dataset that is predicting which drug to presecribe to a patient.

dataset is from: https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification

It is a synthetic dataset that reflects what is encountered in industry. 

```{r}
pred_maint <-read.csv("../data/predictive_maintenance.csv", header=TRUE, sep= ",")
str(pred_maint)
table(pred_maint$Target)
```
#### Independent Variables

**UID**: unique identifier ranging from 1 to 10000

**productID**: consisting of a letter L, M, or H for low (50% of all products), medium (30%), and high (20%) as product quality variants and a variant-specific serial number

**type**: consisting of the letter L, M or H from the productID.

**air temperature [K]**: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K

**process temperature [K]**: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.

**rotational speed [rpm]**: calculated from powepower of 2860 W, overlaid with a normally distributed noise

**torque [Nm]**: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.

**tool wear [min]**: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a
'machine failure' label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true.

#### Dependent Variables

**target**: A target variable that indicates that a failure occurred.

**Failure_Type**: The type of failure that occurred.

### Dataset preparation
- Limit the dataset to where "target" == 1 so that we only have occurrences of failures
- Remove unnecessary variables like UID, Product_ID, and Target
- change remaining chr types to factors

```{r}
# limit the predict failure dataframe to only when failures occurred
pred_failure <- pred_maint[pred_maint$Target ==1,]
pred_failure <- pred_failure[pred_failure$Failure_Type != "No Failure",]
pred_failure <- pred_failure[,!names(pred_failure) %in% c("UDI", "Product_ID", "Target")]

# set the chr types to factors
pred_failure$Type <- as.factor(pred_failure$Type)
pred_failure$Failure_Type <- as.factor(pred_failure$Failure_Type)
str(pred_failure)
```
# Check for our assumptions:

## Check that the independent variables are linear with the predicted variable

```{r}
model <- glm(Failure_Type ~ Air_temperature_K + Process_temperature_K + Rotational_speed_rpm + Torque_Nm + Tool.wear_min, data = pred_failure)
```
## Ensure that each observation is independent from the others

We can intuitively confirm that each observation is independent from the others because there isn't any interaction between each machine.

## Check for multicollinearity between variables

```{r}
num_vars <- c("Air_temperature_K", "Process_temperature_K", "Rotational_speed_rpm", "Torque_Nm", "Tool.wear_min")
M <- cor(pred_failure[num_vars])
corrplot(M, method="circle")
```
It looks like we have two pairs of variables that are highly correlated with each other, so we will have to remove one of each respectively.:

- Process_temperature_K is correlated with Air_temperature_K 
- Rotational_Speed_rpm is negatively correlated with Torque

After running iterations with different pairs it looks like Air_temperature_K and Rotational_speed_rpm gives us our best accuracy. 


```{r}
pred_failure_lim <- pred_failure[c("Type", "Process_temperature_K", "Rotational_speed_rpm", "Tool.wear_min", "Failure_Type")]
str(pred_failure_lim)
```
## Data preparation:
Making Process_temperature_K a standard scale

```{r}
# scaling the process_temperature_K to put it in a more standard range
pred_failure_lim$Process_temperature_K <- scale(pred_failure_lim$Process_temperature_K)

```

## Splitting the data in train and test

```{r}
set.seed(424242) # setting the seed to always get the same train/test split
#Splitting the data using a function from dplyr package
index <- createDataPartition(pred_failure_lim$Failure_Type, p = .80, list = FALSE)
train <- pred_failure_lim[index,]
test <- pred_failure_lim[-index,]

```

## Train the model

```{r}
set.seed(424242) # setting the seed to always get the same model_fit
# Training the multinomial model
multinom_model <- multinom(Failure_Type ~ ., data = train)

# Checking the model
summary(multinom_model)
```

### Get model coefficients

```{r}
exp(coef(multinom_model))
```
As we expected the main coefficient impacting Overstrain Failure is Tool.wear_min for Type L
Power failure and Tool Wear Failure's main impact is rotational_speed and tool_wear but they are effected differently from the Type.

### Predicting Failure Type on Train Dataset

```{r}
# Predicting the values for train dataset
train$Failure_Predicted <- predict(multinom_model, newdata = train, "class")
# Building classification table
tab <- table(train$Failure_Type, train$Failure_Predicted)

cm <- confusionMatrix(train$Failure_Predicted, train$Failure_Type)
cm_class <- cm$byClass
cm
recall <- mean(cm_class[,"Sensitivity"])
recall
precision <- mean(cm_class[,"Pos Pred Value"])
precision
```
It looks like with the train set that we have 73% accuracy, 73% recall (Sensitivity) and 75% precision (Pos Pred Value)

### Predicting Failure Type on Test Dataset

```{r}


# Predicting the class for test dataset
test$Failure_Predicted <- predict(multinom_model, newdata = test, "class")
# Building classification table
#tab <- table(test$Failure_Type, test$Failure_Predicted)
#tab
cm <-confusionMatrix(test$Failure_Predicted, test$Failure_Type)
cm_class <- cm$byClass
cm
recall <- mean(cm_class[,"Sensitivity"])
recall
precision <- mean(cm_class[,"Pos Pred Value"])
precision
```
It looks like with the train set that we have 78% accuracy, 77% recall (Sensitivity) and 82% precision (Pos Pred Value)


```{r}


```




