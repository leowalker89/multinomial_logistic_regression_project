---
title: "Code_Handout"
author: "Jackie Vogel, Sarah Millard, Ignacio Luque, Leo Walker"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# installing caret for train/test split
library(caret)
library(nnet)
library(corrplot)
library(ggplot2)
```

## Multinomial Logistic Regression

This R Markdown demonstrates how to use Multinomial Logistic Regression on a dataset that is predicting the type of machine failure based on several different variables.

dataset is from: https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification

It is a synthetic dataset that reflects what is encountered in industry. 

```{r}
pred_maint <-read.csv("../data/predictive_maintenance.csv", header=TRUE, sep= ",")
str(pred_maint)
table(pred_maint$Target)
```
#### Independent Variables

**UID**: unique identifier ranging from 1 to 10000

**productID**: consisting of a letter L, M, or H for low (50% of all products), medium (30%), and high (20%) as product quality variants and a variant-specific serial number

**type**: consisting of the letter L, M or H from the productID.

**air temperature [K]**: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K

**process temperature [K]**: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.

**rotational speed [rpm]**: calculated from powepower of 2860 W, overlaid with a normally distributed noise

**torque [Nm]**: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.

**tool wear [min]**: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a
'machine failure' label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true.

#### Dependent Variables

**target**: A target variable that indicates that a failure occurred. 0 indicates No Failure, 1 indicates some type of Failure.

**Failure_Type**: The type of failure that occurred. The types are: No Failure and Random Failures which occur when target is 0; Power Failure, Tool Wear Failure, Overstrain Failure, and Heat Dissipation Failure which occur when target is 1.

#### Research Question
Using multinomial logistic regression on this data set, we can predict what type of machine failure will occur based on the type of wear it has seen. 

### Dataset preparation
- Limit the dataset to where "target" == 1 so that we only have occurrences of failures
- Remove unnecessary variables like UID, Product_ID, and Target
- change remaining chr types to factors

```{r}
# limit the predict failure dataframe to only when failures occurred
pred_failure <- pred_maint[pred_maint$Target ==1,]
pred_failure <- pred_failure[pred_failure$Failure_Type != "No Failure",]
pred_failure <- pred_failure[,!names(pred_failure) %in% c("UDI", "Product_ID", "Target")]

# set the chr types to factors
pred_failure$Type <- as.factor(pred_failure$Type)
pred_failure$Failure_Type <- as.factor(pred_failure$Failure_Type)
str(pred_failure)
```

## Check for multicollinearity between variables or other exploratory data analysis/descriptive analysis?

```{r}
num_vars <- c("Air_temperature_K", "Process_temperature_K", "Rotational_speed_rpm", "Torque_Nm", "Tool.wear_min")
M <- cor(pred_failure[num_vars])
corrplot(M, method="circle")
```
It looks like we have two pairs of variables that are highly correlated with each other, so we will have to remove one of each respectively.:

- Process_temperature_K is correlated with Air_temperature_K 
- Rotational_Speed_rpm is negatively correlated with Torque

After running iterations with different pairs it looks like Air_temperature_K and Rotational_speed_rpm gives us our best accuracy. 

```{r}
pred_failure_lim <- pred_failure[c("Type", "Process_temperature_K", "Rotational_speed_rpm", "Tool.wear_min", "Failure_Type")]
str(pred_failure_lim)
```
```{r}
ggplot(pred_failure_lim, aes(x = Failure_Type, y = Process_temperature_K)) +
  geom_violin() + guides(fill = guide_legend(title = "Failure Type vs Air Temperature (K)"))

ggplot(pred_failure_lim, aes(x = Failure_Type, y = Rotational_speed_rpm )) +
  geom_violin() + guides(fill = guide_legend(title = "Failure Type vs Rotational_speed_rpm"))

ggplot(pred_failure_lim, aes(x = Failure_Type, y = Tool.wear_min)) +
  geom_violin() + guides(fill = guide_legend(title = "Failure Type vs Tool Wear"))
```
From the box plots it looks like :
- Heat Dissipation Failures mainly occur where the process_temperature isn't low (around 302 degrees K).
- That if a failure happens at high rotational speeds that it was most likely a power failure or tool wear failure. 
- Overstrain Failure and Tool Wear Failures happen with high tool wear mins.

```{r}
# scaling the process_temperature_K to put it in a more standard range
pred_failure_lim$Process_temperature_K <- scale(pred_failure_lim$Process_temperature_K)

```

## Splitting the data in train and test

```{r}
set.seed(424242) # setting the seed to always get the same train/test split
#Splitting the data using a function from dplyr package
index <- createDataPartition(pred_failure_lim$Failure_Type, p = .80, list = FALSE)
train <- pred_failure_lim[index,]
test <- pred_failure_lim[-index,]

```

## Train the model

```{r}
set.seed(424242) # setting the seed to always get the same model_fit
# Training the multinomial model
multinom_model <- multinom(Failure_Type ~ ., data = train)

# Checking the model
summary(multinom_model)
```
### Get model coefficients

```{r}
exp(coef(multinom_model))
```
As we expected the main coefficient impacting Overstrain Failure is Tool.wear_min for Type L
Power failure and Tool Wear Failure's main impact is rotational_speed and tool_wear but they are effected differently from the Type.

### Predicting Failure Type on Train Dataset

```{r}
# Predicting the values for train dataset
train$Failure_Predicted <- predict(multinom_model, newdata = train, "class")
# Building classification table
tab <- table(train$Failure_Type, train$Failure_Predicted)

cm <- confusionMatrix(train$Failure_Predicted, train$Failure_Type)
cm_class <- cm$byClass
cm
recall <- mean(cm_class[,"Sensitivity"])
recall
precision <- mean(cm_class[,"Pos Pred Value"])
precision
```
It looks like with the train set that we have 73% accuracy, 73% recall (Sensitivity) and 75% precision (Pos Pred Value)

### Predicting Failure Type on Test Dataset

```{r}


# Predicting the class for test dataset
test$Failure_Predicted <- predict(multinom_model, newdata = test, "class")
# Building classification table
tab <- table(test$Failure_Type, test$Failure_Predicted)
tab
cm <-confusionMatrix(test$Failure_Predicted, test$Failure_Type)
cm_class <- cm$byClass
cm
recall <- mean(cm_class[,"Sensitivity"])
recall
precision <- mean(cm_class[,"Pos Pred Value"])
precision
```
It looks like with the train set that we have 78% accuracy, 77% recall (Sensitivity) and 82% precision (Pos Pred Value)


```{r}


```




